{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6504, 2794) (5114, 920)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# read stata data files\n",
    "df_wave1 = pd.read_stata('21600-0001-Data.dta')\n",
    "df_wave4 = pd.read_stata('21600-0022-Data.dta')\n",
    "print(df_wave1.shape, df_wave4.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AID</th>\n",
       "      <th>IMONTH</th>\n",
       "      <th>IDAY</th>\n",
       "      <th>IYEAR</th>\n",
       "      <th>SCH_YR</th>\n",
       "      <th>BIO_SEX</th>\n",
       "      <th>VERSION</th>\n",
       "      <th>SMP01</th>\n",
       "      <th>SMP03</th>\n",
       "      <th>H1GI1M</th>\n",
       "      <th>...</th>\n",
       "      <th>PD4A</th>\n",
       "      <th>PD4B</th>\n",
       "      <th>PD4C</th>\n",
       "      <th>PD4D</th>\n",
       "      <th>PD4E</th>\n",
       "      <th>PD4F</th>\n",
       "      <th>PD5</th>\n",
       "      <th>PD5A</th>\n",
       "      <th>AH_PVT</th>\n",
       "      <th>AH_RAW</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>57100270</td>\n",
       "      <td>(6) June</td>\n",
       "      <td>23</td>\n",
       "      <td>(95) 1995</td>\n",
       "      <td>(1) Yes</td>\n",
       "      <td>(2) Female</td>\n",
       "      <td>4</td>\n",
       "      <td>(0) No</td>\n",
       "      <td>(1) Yes</td>\n",
       "      <td>(10) October</td>\n",
       "      <td>...</td>\n",
       "      <td>(7) Legitimate skip (adolescent not a twin)</td>\n",
       "      <td>(7) Legitimate skip (adolescent not a twin)</td>\n",
       "      <td>(7) Legitimate skip (adolescent not a twin)</td>\n",
       "      <td>(7) Legitimate skip (adolescent not a twin)</td>\n",
       "      <td>(7) Legitimate skip (adolescent not a twin)</td>\n",
       "      <td>(7) Legitimate skip (adolescent not a twin)</td>\n",
       "      <td>(1) Yes</td>\n",
       "      <td>(1) Yes</td>\n",
       "      <td>86.0</td>\n",
       "      <td>55.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>57101310</td>\n",
       "      <td>(5) May</td>\n",
       "      <td>5</td>\n",
       "      <td>(95) 1995</td>\n",
       "      <td>(1) Yes</td>\n",
       "      <td>(2) Female</td>\n",
       "      <td>1</td>\n",
       "      <td>(1) Yes</td>\n",
       "      <td>(0) No</td>\n",
       "      <td>(11) November</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>88.0</td>\n",
       "      <td>58.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>57103171</td>\n",
       "      <td>(6) June</td>\n",
       "      <td>27</td>\n",
       "      <td>(95) 1995</td>\n",
       "      <td>(0) No</td>\n",
       "      <td>(1) Male</td>\n",
       "      <td>4</td>\n",
       "      <td>(1) Yes</td>\n",
       "      <td>(0) No</td>\n",
       "      <td>(10) October</td>\n",
       "      <td>...</td>\n",
       "      <td>(7) Legitimate skip (adolescent not a twin)</td>\n",
       "      <td>(7) Legitimate skip (adolescent not a twin)</td>\n",
       "      <td>(7) Legitimate skip (adolescent not a twin)</td>\n",
       "      <td>(7) Legitimate skip (adolescent not a twin)</td>\n",
       "      <td>(7) Legitimate skip (adolescent not a twin)</td>\n",
       "      <td>(7) Legitimate skip (adolescent not a twin)</td>\n",
       "      <td>(1) Yes</td>\n",
       "      <td>(0) No</td>\n",
       "      <td>120.0</td>\n",
       "      <td>79.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>57103869</td>\n",
       "      <td>(7) July</td>\n",
       "      <td>14</td>\n",
       "      <td>(95) 1995</td>\n",
       "      <td>(0) No</td>\n",
       "      <td>(1) Male</td>\n",
       "      <td>4</td>\n",
       "      <td>(1) Yes</td>\n",
       "      <td>(0) No</td>\n",
       "      <td>(1) January</td>\n",
       "      <td>...</td>\n",
       "      <td>(7) Legitimate skip (adolescent not a twin)</td>\n",
       "      <td>(7) Legitimate skip (adolescent not a twin)</td>\n",
       "      <td>(7) Legitimate skip (adolescent not a twin)</td>\n",
       "      <td>(7) Legitimate skip (adolescent not a twin)</td>\n",
       "      <td>(7) Legitimate skip (adolescent not a twin)</td>\n",
       "      <td>(7) Legitimate skip (adolescent not a twin)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>85.0</td>\n",
       "      <td>56.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57104553</td>\n",
       "      <td>(7) July</td>\n",
       "      <td>14</td>\n",
       "      <td>(95) 1995</td>\n",
       "      <td>(1) Yes</td>\n",
       "      <td>(2) Female</td>\n",
       "      <td>4</td>\n",
       "      <td>(1) Yes</td>\n",
       "      <td>(0) No</td>\n",
       "      <td>(6) June</td>\n",
       "      <td>...</td>\n",
       "      <td>(7) Legitimate skip (adolescent not a twin)</td>\n",
       "      <td>(7) Legitimate skip (adolescent not a twin)</td>\n",
       "      <td>(7) Legitimate skip (adolescent not a twin)</td>\n",
       "      <td>(7) Legitimate skip (adolescent not a twin)</td>\n",
       "      <td>(7) Legitimate skip (adolescent not a twin)</td>\n",
       "      <td>(7) Legitimate skip (adolescent not a twin)</td>\n",
       "      <td>(1) Yes</td>\n",
       "      <td>(0) No</td>\n",
       "      <td>90.0</td>\n",
       "      <td>59.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 2794 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        AID    IMONTH  IDAY      IYEAR   SCH_YR     BIO_SEX VERSION    SMP01   \n",
       "0  57100270  (6) June    23  (95) 1995  (1) Yes  (2) Female       4   (0) No  \\\n",
       "1  57101310   (5) May     5  (95) 1995  (1) Yes  (2) Female       1  (1) Yes   \n",
       "2  57103171  (6) June    27  (95) 1995   (0) No    (1) Male       4  (1) Yes   \n",
       "3  57103869  (7) July    14  (95) 1995   (0) No    (1) Male       4  (1) Yes   \n",
       "4  57104553  (7) July    14  (95) 1995  (1) Yes  (2) Female       4  (1) Yes   \n",
       "\n",
       "     SMP03         H1GI1M  ...                                         PD4A   \n",
       "0  (1) Yes   (10) October  ...  (7) Legitimate skip (adolescent not a twin)  \\\n",
       "1   (0) No  (11) November  ...                                          NaN   \n",
       "2   (0) No   (10) October  ...  (7) Legitimate skip (adolescent not a twin)   \n",
       "3   (0) No    (1) January  ...  (7) Legitimate skip (adolescent not a twin)   \n",
       "4   (0) No       (6) June  ...  (7) Legitimate skip (adolescent not a twin)   \n",
       "\n",
       "                                          PD4B   \n",
       "0  (7) Legitimate skip (adolescent not a twin)  \\\n",
       "1                                          NaN   \n",
       "2  (7) Legitimate skip (adolescent not a twin)   \n",
       "3  (7) Legitimate skip (adolescent not a twin)   \n",
       "4  (7) Legitimate skip (adolescent not a twin)   \n",
       "\n",
       "                                          PD4C   \n",
       "0  (7) Legitimate skip (adolescent not a twin)  \\\n",
       "1                                          NaN   \n",
       "2  (7) Legitimate skip (adolescent not a twin)   \n",
       "3  (7) Legitimate skip (adolescent not a twin)   \n",
       "4  (7) Legitimate skip (adolescent not a twin)   \n",
       "\n",
       "                                          PD4D   \n",
       "0  (7) Legitimate skip (adolescent not a twin)  \\\n",
       "1                                          NaN   \n",
       "2  (7) Legitimate skip (adolescent not a twin)   \n",
       "3  (7) Legitimate skip (adolescent not a twin)   \n",
       "4  (7) Legitimate skip (adolescent not a twin)   \n",
       "\n",
       "                                          PD4E   \n",
       "0  (7) Legitimate skip (adolescent not a twin)  \\\n",
       "1                                          NaN   \n",
       "2  (7) Legitimate skip (adolescent not a twin)   \n",
       "3  (7) Legitimate skip (adolescent not a twin)   \n",
       "4  (7) Legitimate skip (adolescent not a twin)   \n",
       "\n",
       "                                          PD4F      PD5     PD5A AH_PVT AH_RAW  \n",
       "0  (7) Legitimate skip (adolescent not a twin)  (1) Yes  (1) Yes   86.0   55.0  \n",
       "1                                          NaN      NaN      NaN   88.0   58.0  \n",
       "2  (7) Legitimate skip (adolescent not a twin)  (1) Yes   (0) No  120.0   79.0  \n",
       "3  (7) Legitimate skip (adolescent not a twin)      NaN      NaN   85.0   56.0  \n",
       "4  (7) Legitimate skip (adolescent not a twin)  (1) Yes   (0) No   90.0   59.0  \n",
       "\n",
       "[5 rows x 2794 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_wave1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AID</th>\n",
       "      <th>IMONTH4</th>\n",
       "      <th>IDAY4</th>\n",
       "      <th>IYEAR4</th>\n",
       "      <th>BIO_SEX4</th>\n",
       "      <th>VERSION4</th>\n",
       "      <th>BREAK_Q</th>\n",
       "      <th>PRYEAR4</th>\n",
       "      <th>PRETEST4</th>\n",
       "      <th>PRISON4</th>\n",
       "      <th>...</th>\n",
       "      <th>H4EO5C</th>\n",
       "      <th>H4EO5D</th>\n",
       "      <th>H4EO5E</th>\n",
       "      <th>H4EO5F</th>\n",
       "      <th>H4EO5G</th>\n",
       "      <th>H4EO5H</th>\n",
       "      <th>H4EO5I</th>\n",
       "      <th>H4EO5J</th>\n",
       "      <th>H4EO6</th>\n",
       "      <th>H4EO7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>57101310</td>\n",
       "      <td>(5) May</td>\n",
       "      <td>6</td>\n",
       "      <td>2008</td>\n",
       "      <td>(2) Female</td>\n",
       "      <td>V5.4</td>\n",
       "      <td>NO</td>\n",
       "      <td>2001</td>\n",
       "      <td>(0) Not a pretest interview</td>\n",
       "      <td>(0) Not a prison interview</td>\n",
       "      <td>...</td>\n",
       "      <td>(0) Not selected</td>\n",
       "      <td>(0) Not selected</td>\n",
       "      <td>(0) Not selected</td>\n",
       "      <td>(0) Not selected</td>\n",
       "      <td>(0) Not selected</td>\n",
       "      <td>(0) Not selected</td>\n",
       "      <td>(0) Not selected</td>\n",
       "      <td>(0) Not selected</td>\n",
       "      <td>(2) Rural town</td>\n",
       "      <td>(1) Very safe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>57103869</td>\n",
       "      <td>(5) May</td>\n",
       "      <td>22</td>\n",
       "      <td>2008</td>\n",
       "      <td>(1) Male</td>\n",
       "      <td>V5.4</td>\n",
       "      <td>NO</td>\n",
       "      <td>2002</td>\n",
       "      <td>(0) Not a pretest interview</td>\n",
       "      <td>(0) Not a prison interview</td>\n",
       "      <td>...</td>\n",
       "      <td>(0) Not selected</td>\n",
       "      <td>(0) Not selected</td>\n",
       "      <td>(0) Not selected</td>\n",
       "      <td>(0) Not selected</td>\n",
       "      <td>(0) Not selected</td>\n",
       "      <td>(0) Not selected</td>\n",
       "      <td>(0) Not selected</td>\n",
       "      <td>(0) Not selected</td>\n",
       "      <td>(4) Urban, residential only</td>\n",
       "      <td>(1) Very safe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>57109625</td>\n",
       "      <td>(11) November</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>(1) Male</td>\n",
       "      <td>V5.5</td>\n",
       "      <td>NO</td>\n",
       "      <td>2002</td>\n",
       "      <td>(0) Not a pretest interview</td>\n",
       "      <td>(0) Not a prison interview</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>57111071</td>\n",
       "      <td>(6) June</td>\n",
       "      <td>29</td>\n",
       "      <td>2008</td>\n",
       "      <td>(1) Male</td>\n",
       "      <td>V5.4</td>\n",
       "      <td>NO</td>\n",
       "      <td>2001</td>\n",
       "      <td>(0) Not a pretest interview</td>\n",
       "      <td>(0) Not a prison interview</td>\n",
       "      <td>...</td>\n",
       "      <td>(0) Not selected</td>\n",
       "      <td>(0) Not selected</td>\n",
       "      <td>(0) Not selected</td>\n",
       "      <td>(0) Not selected</td>\n",
       "      <td>(0) Not selected</td>\n",
       "      <td>(0) Not selected</td>\n",
       "      <td>(0) Not selected</td>\n",
       "      <td>(0) Not selected</td>\n",
       "      <td>(1) Rural farm</td>\n",
       "      <td>(2) Moderately safe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57113943</td>\n",
       "      <td>(11) November</td>\n",
       "      <td>11</td>\n",
       "      <td>2008</td>\n",
       "      <td>(1) Male</td>\n",
       "      <td>V5.5</td>\n",
       "      <td>NO</td>\n",
       "      <td>2002</td>\n",
       "      <td>(0) Not a pretest interview</td>\n",
       "      <td>(0) Not a prison interview</td>\n",
       "      <td>...</td>\n",
       "      <td>(0) Not selected</td>\n",
       "      <td>(0) Not selected</td>\n",
       "      <td>(0) Not selected</td>\n",
       "      <td>(0) Not selected</td>\n",
       "      <td>(0) Not selected</td>\n",
       "      <td>(0) Not selected</td>\n",
       "      <td>(0) Not selected</td>\n",
       "      <td>(0) Not selected</td>\n",
       "      <td>(5) 3 or more commercial properties, mostly re...</td>\n",
       "      <td>(3) Moderately unsafe</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 920 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        AID        IMONTH4  IDAY4  IYEAR4    BIO_SEX4 VERSION4 BREAK_Q   \n",
       "0  57101310        (5) May      6    2008  (2) Female     V5.4      NO  \\\n",
       "1  57103869        (5) May     22    2008    (1) Male     V5.4      NO   \n",
       "2  57109625  (11) November      2    2008    (1) Male     V5.5      NO   \n",
       "3  57111071       (6) June     29    2008    (1) Male     V5.4      NO   \n",
       "4  57113943  (11) November     11    2008    (1) Male     V5.5      NO   \n",
       "\n",
       "   PRYEAR4                     PRETEST4                     PRISON4  ...   \n",
       "0     2001  (0) Not a pretest interview  (0) Not a prison interview  ...  \\\n",
       "1     2002  (0) Not a pretest interview  (0) Not a prison interview  ...   \n",
       "2     2002  (0) Not a pretest interview  (0) Not a prison interview  ...   \n",
       "3     2001  (0) Not a pretest interview  (0) Not a prison interview  ...   \n",
       "4     2002  (0) Not a pretest interview  (0) Not a prison interview  ...   \n",
       "\n",
       "             H4EO5C            H4EO5D            H4EO5E            H4EO5F   \n",
       "0  (0) Not selected  (0) Not selected  (0) Not selected  (0) Not selected  \\\n",
       "1  (0) Not selected  (0) Not selected  (0) Not selected  (0) Not selected   \n",
       "2               NaN               NaN               NaN               NaN   \n",
       "3  (0) Not selected  (0) Not selected  (0) Not selected  (0) Not selected   \n",
       "4  (0) Not selected  (0) Not selected  (0) Not selected  (0) Not selected   \n",
       "\n",
       "             H4EO5G            H4EO5H            H4EO5I            H4EO5J   \n",
       "0  (0) Not selected  (0) Not selected  (0) Not selected  (0) Not selected  \\\n",
       "1  (0) Not selected  (0) Not selected  (0) Not selected  (0) Not selected   \n",
       "2               NaN               NaN               NaN               NaN   \n",
       "3  (0) Not selected  (0) Not selected  (0) Not selected  (0) Not selected   \n",
       "4  (0) Not selected  (0) Not selected  (0) Not selected  (0) Not selected   \n",
       "\n",
       "                                               H4EO6                  H4EO7  \n",
       "0                                     (2) Rural town          (1) Very safe  \n",
       "1                        (4) Urban, residential only          (1) Very safe  \n",
       "2                                                NaN                    NaN  \n",
       "3                                     (1) Rural farm    (2) Moderately safe  \n",
       "4  (5) 3 or more commercial properties, mostly re...  (3) Moderately unsafe  \n",
       "\n",
       "[5 rows x 920 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_wave4.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5114, 3713)\n"
     ]
    }
   ],
   "source": [
    "# merge on AID (inner)\n",
    "df_merged = pd.merge(df_wave1, df_wave4, on='AID', how='inner')\n",
    "print(df_merged.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select relevant columns\n",
    "\n",
    "Y_delinquency = 'H1DS5'\n",
    "Y_depression = 'H1FS6'\n",
    "\n",
    "Z_mother = 'H4WP3'\n",
    "Z_father = 'H4WP9'\n",
    "\n",
    "covariates = ['H1GI1Y', 'IYEAR', # birth year/year of interview\n",
    "              'BIO_SEX', # gender\n",
    "              'H1GI6A', 'H1GI6B', 'H1GI6C', 'H1GI6D', 'H1GI6E', # race\n",
    "              'H4MA3', # physical abuse\n",
    "              'H4MA5', # sexual abuse\n",
    "              ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "H1DS5\n",
       "(0) Never              3481\n",
       "(1) 1 or 2 times       1162\n",
       "(2) 3 or 4 times        239\n",
       "(3) 5 or more times     203\n",
       "(6) Refused              21\n",
       "(8) Don't know            8\n",
       "(9) Not applicable        0\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged[Y_delinquency].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "H1FS6\n",
       "(0) Never/rarely            3147\n",
       "(1) Sometimes               1462\n",
       "(2) A lot of the time        346\n",
       "(3) Most/all of the time     149\n",
       "(8) Don't know                 6\n",
       "(6) Refused                    4\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged[Y_depression].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['(0) No', '(1) Yes', '(8) Don't know', '(6) Refused']\n",
       "Categories (4, object): ['(0) No' < '(1) Yes' < '(6) Refused' < '(8) Don't know']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged[Z_mother].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y_delinquency\n",
      "0.0    3481\n",
      "1.0    1604\n",
      "Name: count, dtype: int64\n",
      "Y_depression\n",
      "0.0    3147\n",
      "1.0    1957\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# process outcome variables\n",
    "\n",
    "df_merged['Y_delinquency'] = 1\n",
    "df_merged.loc[df_merged[Y_delinquency] == '(0) Never', 'Y_delinquency'] = 0\n",
    "df_merged.loc[df_merged[Y_delinquency] == '(6) Refused', 'Y_delinquency'] = np.nan\n",
    "df_merged.loc[df_merged[Y_delinquency] == '(8) Don\\'t know', 'Y_delinquency'] = np.nan\n",
    "df_merged.loc[df_merged[Y_delinquency] == '(9) Not applicable', 'Y_delinquency'] = np.nan\n",
    "print(df_merged['Y_delinquency'].value_counts())\n",
    "\n",
    "df_merged['Y_depression'] = 1\n",
    "df_merged.loc[df_merged[Y_depression] == '(0) Never/rarely', 'Y_depression'] = 0\n",
    "df_merged.loc[df_merged[Y_depression] == '(6) Refused', 'Y_depression'] = np.nan\n",
    "df_merged.loc[df_merged[Y_depression] == '(8) Don\\'t know', 'Y_depression'] = np.nan\n",
    "print(df_merged['Y_depression'].value_counts())\n",
    "\n",
    "selected_columns = ['Y_delinquency', 'Y_depression']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "H4WP3\n",
       "(0) No            4888\n",
       "(1) Yes            177\n",
       "(8) Don't know      48\n",
       "(6) Refused          1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged[Z_mother].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "H4WP9\n",
       "(0) No            4093\n",
       "(1) Yes            727\n",
       "(8) Don't know     292\n",
       "(6) Refused          2\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged[Z_father].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Z_mother\n",
      "0.0    4888\n",
      "1.0     177\n",
      "Name: count, dtype: int64\n",
      "Z_father\n",
      "0.0    4093\n",
      "1.0     727\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# process treatment variables\n",
    "\n",
    "df_merged['Z_mother'] = 1\n",
    "df_merged.loc[df_merged[Z_mother] == '(0) No', 'Z_mother'] = 0\n",
    "df_merged.loc[df_merged[Z_mother] == '(6) Refused', 'Z_mother'] = np.nan\n",
    "df_merged.loc[df_merged[Z_mother] == '(8) Don\\'t know', 'Z_mother'] = np.nan\n",
    "print(df_merged['Z_mother'].value_counts())\n",
    "\n",
    "df_merged['Z_father'] = 1\n",
    "df_merged.loc[df_merged[Z_father] == '(0) No', 'Z_father'] = 0\n",
    "df_merged.loc[df_merged[Z_father] == '(6) Refused', 'Z_father'] = np.nan\n",
    "df_merged.loc[df_merged[Z_father] == '(8) Don\\'t know', 'Z_father'] = np.nan\n",
    "print(df_merged['Z_father'].value_counts())\n",
    "\n",
    "selected_columns += ['Z_mother', 'Z_father']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "H1GI1Y\n",
       "(79) 1979       913\n",
       "(77) 1977       899\n",
       "(78) 1978       891\n",
       "(80) 1980       883\n",
       "(81) 1981       723\n",
       "(82) 1982       465\n",
       "(76) 1976       294\n",
       "(75) 1975        30\n",
       "(83) 1983         7\n",
       "(74) 1974         6\n",
       "(96) Refused      3\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged['H1GI1Y'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IYEAR\n",
       "(95) 1995    5113\n",
       "(94) 1994       1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged['IYEAR'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age\n",
      "21.0      6\n",
      "12.0      8\n",
      "20.0     30\n",
      "19.0    294\n",
      "13.0    464\n",
      "14.0    723\n",
      "15.0    883\n",
      "17.0    891\n",
      "18.0    899\n",
      "16.0    913\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# process covariates\n",
    "\n",
    "# 1. age\n",
    "df_merged['birth_year'] = df_merged['H1GI1Y'].apply(lambda x: int(x[1:3])).astype(int)\n",
    "df_merged.loc[df_merged['birth_year'] == 96, 'birth_year'] = np.nan\n",
    "df_merged['interview_year'] = df_merged['IYEAR'].apply(lambda x: int(x[1:3])).astype(int)\n",
    "df_merged['age'] = df_merged['interview_year'] - df_merged['birth_year']\n",
    "df_merged['age'].describe()\n",
    "print(df_merged['age'].value_counts(ascending=True))\n",
    "\n",
    "selected_columns += ['age']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BIO_SEX\n",
       "(2) Female     2760\n",
       "(1) Male       2353\n",
       "(6) Refused       1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged['BIO_SEX'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "female\n",
      "1.0    2760\n",
      "0.0    2353\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 2. gender\n",
    "\n",
    "df_merged['female'] = 1\n",
    "df_merged.loc[df_merged['BIO_SEX'] == '(1) Male', 'female'] = 0\n",
    "df_merged.loc[df_merged['BIO_SEX'] == '(6) Refused', 'female'] = np.nan\n",
    "print(df_merged['female'].value_counts())\n",
    "\n",
    "selected_columns += ['female']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "H1GI6E\n",
       "(0) Not marked    4782\n",
       "(1) Marked         316\n",
       "(8) Don't know      12\n",
       "(6) Refused          4\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 'H1GI6A', 'H1GI6B', 'H1GI6C', 'H1GI6D', 'H1GI6E'\n",
    "\n",
    "df_merged['H1GI6E'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "white\n",
      "1.0    3456\n",
      "0.0    1642\n",
      "Name: count, dtype: int64\n",
      "black\n",
      "0.0    3849\n",
      "1.0    1249\n",
      "Name: count, dtype: int64\n",
      "american\n",
      "0.0    4916\n",
      "1.0     182\n",
      "Name: count, dtype: int64\n",
      "asian\n",
      "0.0    4916\n",
      "1.0     182\n",
      "Name: count, dtype: int64\n",
      "other\n",
      "0.0    4782\n",
      "1.0     316\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 3. race\n",
    "\n",
    "df_merged['white'] = 0\n",
    "df_merged.loc[df_merged['H1GI6A'] == '(1) Marked', 'white'] = 1\n",
    "df_merged.loc[df_merged['H1GI6A'] == '(6) Refused', 'white'] = np.nan\n",
    "df_merged.loc[df_merged['H1GI6A'] == '(8) Don\\'t know', 'white'] = np.nan\n",
    "print(df_merged['white'].value_counts())\n",
    "\n",
    "df_merged['black'] = 0\n",
    "df_merged.loc[df_merged['H1GI6B'] == '(1) Marked', 'black'] = 1\n",
    "df_merged.loc[df_merged['H1GI6B'] == '(6) Refused', 'black'] = np.nan\n",
    "df_merged.loc[df_merged['H1GI6B'] == '(8) Don\\'t know', 'black'] = np.nan\n",
    "print(df_merged['black'].value_counts())\n",
    "\n",
    "df_merged['american'] = 0\n",
    "df_merged.loc[df_merged['H1GI6C'] == '(1) Marked', 'american'] = 1\n",
    "df_merged.loc[df_merged['H1GI6C'] == '(6) Refused', 'american'] = np.nan\n",
    "df_merged.loc[df_merged['H1GI6C'] == '(8) Don\\'t know', 'american'] = np.nan\n",
    "print(df_merged['american'].value_counts())\n",
    "\n",
    "df_merged['asian'] = 0\n",
    "df_merged.loc[df_merged['H1GI6D'] == '(1) Marked (If Asian/Pacific Islander among R\\'s answer ask Q', 'asian'] = 1\n",
    "df_merged.loc[df_merged['H1GI6D'] == '(6) Refused (skip to Q.8)', 'asian'] = np.nan\n",
    "df_merged.loc[df_merged['H1GI6D'] == '(8) Don\\'t know (skip to Q.8)', 'asian'] = np.nan\n",
    "print(df_merged['asian'].value_counts())\n",
    "\n",
    "df_merged['other'] = 0\n",
    "df_merged.loc[df_merged['H1GI6E'] == '(1) Marked', 'other'] = 1\n",
    "df_merged.loc[df_merged['H1GI6E'] == '(6) Refused', 'other'] = np.nan\n",
    "df_merged.loc[df_merged['H1GI6E'] == '(8) Don\\'t know', 'other'] = np.nan\n",
    "print(df_merged['other'].value_counts())\n",
    "\n",
    "selected_columns += ['white', 'black', 'american', 'asian', 'other']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "H4MA3\n",
       "(6) This has never happened    4171\n",
       "(1) One time                    239\n",
       "(5) More than ten times         223\n",
       "(3) Three to five times         172\n",
       "(2) Two times                   166\n",
       "(4) Six to ten times             80\n",
       "(96) Refused                     32\n",
       "(98) Don't know                  31\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged['H4MA3'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "physical_abuse\n",
      "0.0    4171\n",
      "1.0     880\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 4. physical abuse\n",
    "df_merged['physical_abuse'] = 1\n",
    "df_merged.loc[df_merged['H4MA3'] == '(6) This has never happened', 'physical_abuse'] = 0\n",
    "df_merged.loc[df_merged['H4MA3'] == '(96) Refused', 'physical_abuse'] = np.nan\n",
    "df_merged.loc[df_merged['H4MA3'] == '(98) Don\\'t know', 'physical_abuse'] = np.nan\n",
    "print(df_merged['physical_abuse'].value_counts())\n",
    "\n",
    "selected_columns += ['physical_abuse']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "H4MA5\n",
       "(6) This has never happened    4801\n",
       "(1) One time                     88\n",
       "(3) Three to five times          53\n",
       "(5) More than ten times          50\n",
       "(2) Two times                    40\n",
       "(96) Refused                     32\n",
       "(4) Six to ten times             26\n",
       "(98) Don't know                  24\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged['H4MA5'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sexual_abuse\n",
      "0.0    4801\n",
      "1.0     257\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 5. sexual abuse\n",
    "df_merged['sexual_abuse'] = 1\n",
    "df_merged.loc[df_merged['H4MA5'] == '(6) This has never happened', 'sexual_abuse'] = 0\n",
    "df_merged.loc[df_merged['H4MA5'] == '(96) Refused', 'sexual_abuse'] = np.nan\n",
    "df_merged.loc[df_merged['H4MA5'] == '(98) Don\\'t know', 'sexual_abuse'] = np.nan\n",
    "print(df_merged['sexual_abuse'].value_counts())\n",
    "\n",
    "selected_columns += ['sexual_abuse']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4692, 13)\n",
      "   Y_delinquency  Y_depression  Z_mother  Z_father   age  female  white   \n",
      "0            0.0           0.0       0.0       0.0  19.0     1.0    0.0  \\\n",
      "1            1.0           1.0       0.0       1.0  18.0     0.0    0.0   \n",
      "2            1.0           0.0       0.0       0.0  14.0     0.0    1.0   \n",
      "3            1.0           1.0       0.0       0.0  14.0     0.0    1.0   \n",
      "4            0.0           0.0       0.0       1.0  16.0     0.0    0.0   \n",
      "\n",
      "   black  american  asian  other  physical_abuse  sexual_abuse  \n",
      "0    1.0       0.0    0.0    0.0             0.0           0.0  \n",
      "1    1.0       0.0    0.0    0.0             1.0           1.0  \n",
      "2    0.0       0.0    0.0    0.0             1.0           0.0  \n",
      "3    0.0       0.0    0.0    0.0             0.0           0.0  \n",
      "4    1.0       0.0    0.0    0.0             0.0           0.0  \n"
     ]
    }
   ],
   "source": [
    "# Keep only selected columns\n",
    "\n",
    "df_processed = df_merged[selected_columns].copy()\n",
    "df_processed.dropna(inplace=True)\n",
    "print(df_processed.shape)\n",
    "print(df_processed.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = df_processed['Y_delinquency'].values\n",
    "covariates_names = ['age', 'female', 'white', 'black',\n",
    "       'american', 'asian', 'other', 'physical_abuse', 'sexual_abuse']\n",
    "X = df_processed[covariates_names].values\n",
    "Z = np.zeros(len(Y))\n",
    "G = np.zeros(len(Y))\n",
    "G[(df_processed['Z_mother'] == 1)&(df_processed['Z_father'] == 0)] = 1\n",
    "G[(df_processed['Z_mother'] == 0)&(df_processed['Z_father'] == 1)] = 2\n",
    "G[(df_processed['Z_mother'] == 1)&(df_processed['Z_father'] == 1)] = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from scipy import stats\n",
    "\n",
    "\n",
    "class IPW:\n",
    "    \n",
    "    def __init__(self, Xc, Y, Z, G):\n",
    "        self.Z = np.squeeze(Z)\n",
    "        self.Xc = Xc\n",
    "        self.regressor = np.concatenate((self.Xc,),axis=1)\n",
    "        self.Y = np.squeeze(Y)\n",
    "        self.G = np.squeeze(G)\n",
    "        self.N = Xc.shape[0]\n",
    "        self.prop_idv, self.prop_neigh = self.est_propensity()\n",
    "        self.sigXc = self.get_variance()\n",
    "        \n",
    "    def get_variance(self):\n",
    "        model = LinearRegression().fit(self.regressor, self.Y)\n",
    "        yhat = model.predict(self.regressor)\n",
    "        sighat = (self.Y - yhat)**2\n",
    "        #sighat = np.std(self.Y)\n",
    "        return sighat\n",
    "\n",
    "    def est_propensity(self):\n",
    "        prop_idv = 0\n",
    "        neigh = LogisticRegression(random_state=0,solver='newton-cg',\n",
    "                                   multi_class='multinomial').fit(self.regressor, self.G)\n",
    "        prop_neigh = neigh.predict_proba(self.regressor)\n",
    "        return prop_idv, prop_neigh\n",
    "\n",
    "    def est(self):\n",
    "        result_0 = {'tau(0,g)': np.zeros(4), 'se': np.zeros(4), 'se est': np.zeros(4), 'p value': np.zeros(4)}\n",
    "        \n",
    "        outcome_model = LinearRegression()\n",
    "        outcome_model.fit(self.Xc[(self.G==0) & (self.Z==0)], self.Y[(self.G==0) & (self.Z==0)])\n",
    "        mu00 = outcome_model.predict(self.Xc)\n",
    "            \n",
    "        for g in range(1,4):\n",
    "            v0g = (self.G == g) * (1 - self.Z)/(self.prop_neigh[:,g]*(1-self.prop_idv))\n",
    "            v00 = (self.G == 0) * (1 - self.Z)/(self.prop_neigh[:,0]*(1-self.prop_idv))\n",
    "            \n",
    "            # IPW estimator\n",
    "            summand_0 = self.Y * v0g/(np.sum(v0g))*self.N - self.Y * v00/(np.sum(v00))*self.N\n",
    "            \n",
    "            # AIPW estimator\n",
    "            outcome_model = LinearRegression()\n",
    "            outcome_model.fit(self.Xc[(self.G==g) & (self.Z==0)], self.Y[(self.G==g) & (self.Z==0)])\n",
    "            mu0g = outcome_model.predict(self.Xc)\n",
    "            summand_0 = (self.Y - mu0g) * v0g/(np.sum(v0g)/self.N) - (self.Y - mu00) * v00/(np.sum(v00)/self.N) + mu0g - mu00\n",
    "            \n",
    "            result_0['tau(0,g)'][g] = np.mean(summand_0)\n",
    "            result_0['se'][g] = np.sqrt(np.var(summand_0)/self.N)\n",
    "            bound_est = np.mean(self.sigXc**2/(1-self.prop_idv) * \n",
    "                            (1/self.prop_neigh[:,g] + 1/self.prop_neigh[:,0]))\n",
    "            result_0['se est'][g] = np.sqrt(bound_est/self.N)\n",
    "            result_0['p value'][g] = 2 * (1 - stats.t.cdf(np.abs(result_0['tau(0,g)'][g]/result_0['se est'][g]), np.sum(self.G==g) - self.Xc.shape[1]))\n",
    "            \n",
    "        \n",
    "        return result_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tau(0,g)': array([0.        , 0.18544597, 0.11767861, 0.19927807]),\n",
       " 'se': array([0.        , 0.06482623, 0.02200261, 0.06552749]),\n",
       " 'se est': array([0.        , 0.03698697, 0.01258986, 0.03982072]),\n",
       " 'p value': array([0.00000000e+00, 4.15569570e-06, 0.00000000e+00, 5.20394286e-06])}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ipw_estimator = IPW(X, Y, Z, G)\n",
    "results_0 = ipw_estimator.est()\n",
    "results_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tau(0,g)': array([0.        , 0.00770644, 0.04236861, 0.17279601]),\n",
       " 'se': array([0.        , 0.06490782, 0.02203248, 0.06590551]),\n",
       " 'se est': array([0.        , 0.03657372, 0.01224703, 0.03904679]),\n",
       " 'p value': array([0.00000000e+00, 8.33753396e-01, 5.78178608e-04, 4.13012146e-05])}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = df_processed['Y_depression'].values\n",
    "ipw_estimator = IPW(X, Y, Z, G)\n",
    "results_0 = ipw_estimator.est()\n",
    "results_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.038</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.036</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   16.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Mon, 20 May 2024</td> <th>  Prob (F-statistic):</th> <td>8.00e-34</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>13:15:06</td>     <th>  Log-Likelihood:    </th> <td> -3178.8</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  4692</td>      <th>  AIC:               </th> <td>   6384.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  4679</td>      <th>  BIC:               </th> <td>   6468.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    12</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>         <td>HC1</td>       <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>   -0.1551</td> <td>    0.075</td> <td>   -2.076</td> <td> 0.038</td> <td>   -0.302</td> <td>   -0.009</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>   -0.0013</td> <td>    0.056</td> <td>   -0.023</td> <td> 0.982</td> <td>   -0.111</td> <td>    0.109</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>    0.0363</td> <td>    0.021</td> <td>    1.734</td> <td> 0.083</td> <td>   -0.005</td> <td>    0.077</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>    <td>    0.1008</td> <td>    0.060</td> <td>    1.682</td> <td> 0.093</td> <td>   -0.017</td> <td>    0.218</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th>    <td>    0.0315</td> <td>    0.004</td> <td>    7.984</td> <td> 0.000</td> <td>    0.024</td> <td>    0.039</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x5</th>    <td>    0.1240</td> <td>    0.014</td> <td>    8.836</td> <td> 0.000</td> <td>    0.096</td> <td>    0.151</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x6</th>    <td>   -0.0663</td> <td>    0.038</td> <td>   -1.758</td> <td> 0.079</td> <td>   -0.140</td> <td>    0.008</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x7</th>    <td>   -0.0441</td> <td>    0.038</td> <td>   -1.158</td> <td> 0.247</td> <td>   -0.119</td> <td>    0.031</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x8</th>    <td>    0.0377</td> <td>    0.040</td> <td>    0.932</td> <td> 0.351</td> <td>   -0.042</td> <td>    0.117</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x9</th>    <td>    0.0418</td> <td>    0.047</td> <td>    0.886</td> <td> 0.376</td> <td>   -0.051</td> <td>    0.134</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x10</th>   <td>   -0.0318</td> <td>    0.044</td> <td>   -0.729</td> <td> 0.466</td> <td>   -0.117</td> <td>    0.054</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x11</th>   <td>    0.0608</td> <td>    0.019</td> <td>    3.162</td> <td> 0.002</td> <td>    0.023</td> <td>    0.098</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x12</th>   <td>    0.0996</td> <td>    0.035</td> <td>    2.878</td> <td> 0.004</td> <td>    0.032</td> <td>    0.167</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>22968.967</td> <th>  Durbin-Watson:     </th> <td>   1.979</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th>  <td> 0.000</td>   <th>  Jarque-Bera (JB):  </th> <td> 683.485</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>           <td> 0.464</td>   <th>  Prob(JB):          </th> <td>3.83e-149</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>       <td> 1.377</td>   <th>  Cond. No.          </th> <td>    207.</td> \n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors are heteroscedasticity robust (HC1)"
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}    &        y         & \\textbf{  R-squared:         } &     0.038   \\\\\n",
       "\\textbf{Model:}            &       OLS        & \\textbf{  Adj. R-squared:    } &     0.036   \\\\\n",
       "\\textbf{Method:}           &  Least Squares   & \\textbf{  F-statistic:       } &     16.00   \\\\\n",
       "\\textbf{Date:}             & Mon, 20 May 2024 & \\textbf{  Prob (F-statistic):} &  8.00e-34   \\\\\n",
       "\\textbf{Time:}             &     13:15:06     & \\textbf{  Log-Likelihood:    } &   -3178.8   \\\\\n",
       "\\textbf{No. Observations:} &        4692      & \\textbf{  AIC:               } &     6384.   \\\\\n",
       "\\textbf{Df Residuals:}     &        4679      & \\textbf{  BIC:               } &     6468.   \\\\\n",
       "\\textbf{Df Model:}         &          12      & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}  &       HC1        & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "               & \\textbf{coef} & \\textbf{std err} & \\textbf{z} & \\textbf{P$> |$z$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{const} &      -0.1551  &        0.075     &    -2.076  &         0.038        &       -0.302    &       -0.009     \\\\\n",
       "\\textbf{x1}    &      -0.0013  &        0.056     &    -0.023  &         0.982        &       -0.111    &        0.109     \\\\\n",
       "\\textbf{x2}    &       0.0363  &        0.021     &     1.734  &         0.083        &       -0.005    &        0.077     \\\\\n",
       "\\textbf{x3}    &       0.1008  &        0.060     &     1.682  &         0.093        &       -0.017    &        0.218     \\\\\n",
       "\\textbf{x4}    &       0.0315  &        0.004     &     7.984  &         0.000        &        0.024    &        0.039     \\\\\n",
       "\\textbf{x5}    &       0.1240  &        0.014     &     8.836  &         0.000        &        0.096    &        0.151     \\\\\n",
       "\\textbf{x6}    &      -0.0663  &        0.038     &    -1.758  &         0.079        &       -0.140    &        0.008     \\\\\n",
       "\\textbf{x7}    &      -0.0441  &        0.038     &    -1.158  &         0.247        &       -0.119    &        0.031     \\\\\n",
       "\\textbf{x8}    &       0.0377  &        0.040     &     0.932  &         0.351        &       -0.042    &        0.117     \\\\\n",
       "\\textbf{x9}    &       0.0418  &        0.047     &     0.886  &         0.376        &       -0.051    &        0.134     \\\\\n",
       "\\textbf{x10}   &      -0.0318  &        0.044     &    -0.729  &         0.466        &       -0.117    &        0.054     \\\\\n",
       "\\textbf{x11}   &       0.0608  &        0.019     &     3.162  &         0.002        &        0.023    &        0.098     \\\\\n",
       "\\textbf{x12}   &       0.0996  &        0.035     &     2.878  &         0.004        &        0.032    &        0.167     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       & 22968.967 & \\textbf{  Durbin-Watson:     } &     1.979  \\\\\n",
       "\\textbf{Prob(Omnibus):} &    0.000  & \\textbf{  Jarque-Bera (JB):  } &   683.485  \\\\\n",
       "\\textbf{Skew:}          &    0.464  & \\textbf{  Prob(JB):          } & 3.83e-149  \\\\\n",
       "\\textbf{Kurtosis:}      &    1.377  & \\textbf{  Cond. No.          } &      207.  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors are heteroscedasticity robust (HC1)"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.038\n",
       "Model:                            OLS   Adj. R-squared:                  0.036\n",
       "Method:                 Least Squares   F-statistic:                     16.00\n",
       "Date:                Mon, 20 May 2024   Prob (F-statistic):           8.00e-34\n",
       "Time:                        13:15:06   Log-Likelihood:                -3178.8\n",
       "No. Observations:                4692   AIC:                             6384.\n",
       "Df Residuals:                    4679   BIC:                             6468.\n",
       "Df Model:                          12                                         \n",
       "Covariance Type:                  HC1                                         \n",
       "==============================================================================\n",
       "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const         -0.1551      0.075     -2.076      0.038      -0.302      -0.009\n",
       "x1            -0.0013      0.056     -0.023      0.982      -0.111       0.109\n",
       "x2             0.0363      0.021      1.734      0.083      -0.005       0.077\n",
       "x3             0.1008      0.060      1.682      0.093      -0.017       0.218\n",
       "x4             0.0315      0.004      7.984      0.000       0.024       0.039\n",
       "x5             0.1240      0.014      8.836      0.000       0.096       0.151\n",
       "x6            -0.0663      0.038     -1.758      0.079      -0.140       0.008\n",
       "x7            -0.0441      0.038     -1.158      0.247      -0.119       0.031\n",
       "x8             0.0377      0.040      0.932      0.351      -0.042       0.117\n",
       "x9             0.0418      0.047      0.886      0.376      -0.051       0.134\n",
       "x10           -0.0318      0.044     -0.729      0.466      -0.117       0.054\n",
       "x11            0.0608      0.019      3.162      0.002       0.023       0.098\n",
       "x12            0.0996      0.035      2.878      0.004       0.032       0.167\n",
       "==============================================================================\n",
       "Omnibus:                    22968.967   Durbin-Watson:                   1.979\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              683.485\n",
       "Skew:                           0.464   Prob(JB):                    3.83e-149\n",
       "Kurtosis:                       1.377   Cond. No.                         207.\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors are heteroscedasticity robust (HC1)\n",
       "\"\"\""
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# run OLS with statsmodel\n",
    "from statsmodels.api import OLS\n",
    "\n",
    "#Y = df_processed['Y_delinquency'].values\n",
    "Y = df_processed['Y_depression'].values\n",
    "I_mother = np.zeros(len(Y))\n",
    "I_mother[(df_processed['Z_mother'] == 1)&(df_processed['Z_father'] == 0)] = 1\n",
    "I_farther = np.zeros(len(Y))\n",
    "I_farther[(df_processed['Z_mother'] == 0)&(df_processed['Z_father'] == 1)] = 1\n",
    "I_both = np.zeros(len(Y))\n",
    "I_both[(df_processed['Z_mother'] == 1)&(df_processed['Z_father'] == 1)] = 1\n",
    "\n",
    "# regress Y on (constant, I_mother, I_father, I_both)\n",
    "regressor = np.concatenate((np.ones((len(Y),1)), I_mother.reshape(-1,1), I_farther.reshape(-1,1), I_both.reshape(-1,1), X), axis=1)\n",
    "# use robust standard errors\n",
    "model = OLS(Y, regressor).fit(cov_type='HC1')\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4692,), (4692, 13))"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "I_mother.shape, df_processed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
